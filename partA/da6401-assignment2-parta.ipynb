{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11337430,"sourceType":"datasetVersion","datasetId":7092365}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#--------------------\n# Necessary Libraries\n#--------------------\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, SubsetRandomSampler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pip install wandb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#----------------------\n# Log in to W&B account\n#----------------------\nimport wandb\nwandb.login(key='150002a34bcf7d04848ccaff65ab76ca5cc3f11b')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-------------------------\n# Inaturalist-dataset path\n#-------------------------\ndata_dir = \"/kaggle/input/inaturalist-dataset/nature_12K/inaturalist_12K\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#---------------------------\n# Show Images from each Class\n#---------------------------\nimport os\nimport matplotlib.pyplot as plt\n\ndataset_path = \"/kaggle/input/inaturalist-dataset/nature_12K/inaturalist_12K/test\"\n\nfor class_name in sorted(os.listdir(dataset_path)):\n    class_dir = os.path.join(dataset_path, class_name)\n    if os.path.isdir(class_dir):\n        img_path = os.path.join(class_dir, os.listdir(class_dir)[2])\n        img = plt.imread(img_path)\n        plt.imshow(img)\n        plt.title(class_name)\n        plt.axis('off')\n        plt.tight_layout()\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part A: Training from scratch\n\n## Question 1\nBuild a small CNN model consisting of $5$ convolution layers. Each convolution layer would be followed by an activation and a max-pooling layer. \n\nAfter $5$ such conv-activation-maxpool blocks, you should have one dense layer followed by the output layer containing $10$ neurons ($1$ for each of the $10$ classes). The input layer should be compatible with the images in the [iNaturalist dataset](https://storage.googleapis.com/wandb_datasets/nature_12K.zip) dataset.","metadata":{}},{"cell_type":"code","source":"#---------------------\n# Define the CNN model\n#---------------------\nclass SimpleCNN(nn.Module):\n    def __init__(self, input_channels, num_filters_list, filter_size, activation_func, dense_neurons, num_classes=10, use_batchnorm=False, dropout_rate=0.0):\n        super(SimpleCNN, self).__init__()\n        self.conv_layers = nn.ModuleList()\n\n        for i in range(5):   # Convolution Layers = 5\n            self.conv_layers.append(\n                nn.Conv2d(input_channels, num_filters_list[i], filter_size, stride=1, padding=0)\n            )\n            if use_batchnorm:\n                self.conv_layers.append(nn.BatchNorm2d(num_filters_list[i]))\n            self.conv_layers.append(activation_func())\n            self.conv_layers.append(nn.MaxPool2d(kernel_size=2, stride=1, padding=0))\n            input_channels = num_filters_list[i]\n\n        # Calculate output size of convolutional layers\n        output_size = self.calculate_output_size(224)  # Assuming input size is 224x224\n\n        self.dense_layer = nn.Linear(input_channels * output_size * output_size, dense_neurons)\n        self.output_layer = nn.Linear(dense_neurons, num_classes)\n        self.dropout = nn.Dropout(dropout_rate)\n        \n    def calculate_output_size(self, input_size):\n        output_size = input_size\n        for layer in self.conv_layers:\n            if isinstance(layer, nn.Conv2d):\n                output_size = (output_size - layer.kernel_size[0] + 2 * layer.padding[0]) // layer.stride[0] + 1\n            elif isinstance(layer, nn.MaxPool2d):\n                output_size = (output_size - layer.kernel_size + 2 * layer.padding) // layer.stride + 1\n        return output_size\n\n    def forward(self, x):\n        for layer in self.conv_layers:\n            x = layer(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(x)  # dropout before the dense layer\n        x = self.dense_layer(x)\n        x = self.output_layer(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-------------------------------\n# Data Loading and Preprocessing\n#-------------------------------\ndef load_and_preprocess_data(data_dir, batch_size, validation_split=0.2):\n    \"\"\"\n    Loads and preprocesses the iNaturalist dataset.\n\n    Args:\n        data_dir (str): The directory containing the train and test folders.\n        batch_size (int): The batch size for training and validation.\n        validation_split (float): The proportion of the training data to use for validation.\n\n    Returns:\n        tuple: DataLoaders for the training and validation sets.\n    \"\"\"\n\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Resize images\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Standardize the pixel values\n    ])\n\n    train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=transform)\n    test_dataset = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=transform)\n\n    # Create data indices for the training and validation splits\n    dataset_size = len(train_dataset)\n    indices = list(range(dataset_size))\n    split = int(np.floor(validation_split * dataset_size))\n    np.random.shuffle(indices) # Shuffle the indices\n    train_indices, val_indices = indices[split:], indices[:split]\n\n    # Create samplers for the training and validation datasets\n    train_sampler = SubsetRandomSampler(train_indices)\n    val_sampler = SubsetRandomSampler(val_indices)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n    val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n\n    return train_loader, val_loader, test_dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-----------------------\n# Training the CNN model\n#-----------------------\ndef train(model, train_loader, val_loader, optimizer, criterion, epochs, device):\n    \"\"\"\n    Trains the CNN model.\n\n    Args:\n        model (nn.Module): The CNN model.\n        train_loader (DataLoader): DataLoader for the training set.\n        val_loader (DataLoader): DataLoader for the validation set.\n        optimizer (optim.Optimizer): The optimizer.\n        criterion (nn.Module): The loss function.\n        epochs (int): The number of epochs to train for.\n        device (torch.device): The device to use for training (CPU or GPU).\n    \"\"\"\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Train loss and Accuracy\n            train_loss += loss.item() * labels.size(0)  # Accumulate loss\n            _, predicted = torch.max(outputs.data, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n        avg_train_loss = train_loss / total\n        train_accuracy = correct / total\n\n        # Validation\n        model.eval()\n        val_correct = 0\n        val_total = 0\n        val_loss = 0.0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images = images.to(device)\n                labels = labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * labels.size(0)\n                _, predicted = torch.max(outputs.data, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n                \n        avg_val_loss = val_loss / val_total\n        val_accuracy = val_correct / val_total\n\n        # Log in wandb\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": avg_train_loss,\n            \"train_accuracy\": train_accuracy,\n            \"val_loss\": avg_val_loss,\n            \"val_accuracy\": val_accuracy\n        })\n        print(f\"Epoch [{epoch+1}/{epochs}], Validation Accuracy: {val_accuracy:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#---------------------------------------------------------------------\n# Function to convert string activation to PyTorch activation function\n#---------------------------------------------------------------------\ndef get_activation(activation_str):\n    if activation_str == 'ReLU':\n        return nn.ReLU\n    elif activation_str == 'GELU':\n        return nn.GELU\n    elif activation_str == 'SiLU':\n        return nn.SiLU\n    elif activation_str == 'Mish':\n        return nn.Mish\n    else:\n        raise ValueError(f\"Invalid activation function: {activation_str}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#--------------------------\n# Wandb Sweep Configuration\n#---------------------------\nsweep_config = {\n    \"method\": \"bayes\",  # Bayesian optimization for efficiency\n    'metric': {\n        'name': 'val_accuracy',\n        'goal': 'maximize'   \n    },\n    \"early_terminate\": {\n        \"type\": \"hyperband\",\n        \"min_iter\": 3  # At least 3 epochs before being evaluated for early stopping\n    },\n    'parameters': {\n        'epochs': {\n            \"values\": [5, 10]\n        },\n        'num_filters': {\n            'values': [32, 64]\n        },\n        'activation': {\n            'values': ['ReLU', 'GELU', 'SiLU', 'Mish']\n        },\n        'filter_organization': {\n            'values': ['same', 'doubling', 'halving']\n        },\n        'data_augmentation': {\n            'values': [True, False]\n        },\n        'batch_norm': {\n            'values': [True, False]\n        },\n        'dropout': {\n            'values': [0.2, 0.3]\n        },\n        'batch_size': {\n            'values': [32, 64]\n        },\n        'learning_rate': {\n            'values': [1e-3, 1e-4]\n        }\n    }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#---------------------\n# Wandb Sweep Function\n#---------------------\ndef wandb_sweep():\n    \"\"\"\n    Performs a hyperparameter sweep using Wandb.\n    \"\"\"\n\n    wandb.init(project=\"iNaturalist-CNN\")\n\n    # Access sweep configuration from wandb\n    config = wandb.config\n\n    # Run name\n    run_name = f\"ep-{config.epochs}_hf-{config.num_filters}_ac-{config.activation}_fo-{config.filter_organization}_da-{config.data_augmentation}_bn-{config.batch_norm}_dro-{config.dropout}_bs-{config.batch_size}_lr-{config.learning_rate}\"\n    wandb.run.name = run_name\n\n    # Data Loading\n    data_dir = \"/kaggle/input/inaturalist-dataset/nature_12K/inaturalist_12K\"\n    train_loader, val_loader, test_dataset = load_and_preprocess_data(data_dir, config.batch_size)\n\n    # Determine filter list based on organization\n    if config.filter_organization == 'same':\n        num_filters_list = [config.num_filters] * 5\n    elif config.filter_organization == 'doubling':\n        num_filters_list = [config.num_filters * (2**i) for i in range(5)]\n    elif config.filter_organization == 'halving':\n        num_filters_list = [config.num_filters // (2**i) if config.num_filters // (2**i) > 0 else 1 for i in range(5)]\n    else:\n        raise ValueError(\"Invalid filter organization\")\n\n    # Model Initialization\n    activation_func = get_activation(config.activation)\n    model = SimpleCNN(3, num_filters_list, 3, activation_func, 128, 10, config.batch_norm, config.dropout)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n\n    # Loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n\n    # Training\n    train(model, train_loader, val_loader, optimizer, criterion, epochs=config.epochs, device=device)\n\n    # Evaluate on test set\n    test_loader = DataLoader(test_dataset, batch_size=config.batch_size)\n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in test_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        accuracy = correct / total\n        print(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    sweep_id = wandb.sweep(sweep_config, project=\"iNaturalist-CNN\")\n    wandb.agent(sweep_id, wandb_sweep, count=29)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Best Hyperparameter Configuration**\n\n```yaml\nactivation:\n    value: SiLU\nbatch_norm:\n    value: True\nbatch_size:\n    value: 64\ndata_augmentation:\n    value: False\ndropout:\n    value: 0.3\nepochs:\n    value: 5\nfilter_organization:\n    value: doubling\nlearning_rate:\n    value: 0.0001\nnum_filters:\n    value: 64\n```","metadata":{}}]}